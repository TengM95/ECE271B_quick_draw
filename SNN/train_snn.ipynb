{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN(nn.Module):\n",
    "    def __init__(self, basenet):\n",
    "        super().__init__()\n",
    "        self.basenet = basenet\n",
    "        self.linear1 = nn.Linear(1000,10)\n",
    "        self.linear2 = nn.Linear(1000,10)\n",
    "        \n",
    "        self.cos = nn.CosineSimilarity()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, pos, neg):\n",
    "        res = []\n",
    "        # Siamese nets; sharing weights\n",
    "        x = self.basenet(pos)\n",
    "        res.append(self.linear1(x))\n",
    "        x = self.basenet(neg)\n",
    "        res.append(self.linear2(x))\n",
    "        \n",
    "        score = self.sigmoid(self.cos(res[0],res[1]))\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: initialize the hyperparameters/variables\n",
    "# Setup: initialize the hyperparameters/variables\n",
    "num_epochs = 10           # Number of full passes through the dataset\n",
    "batch_size = 64       # Number of samples in each minibatch\n",
    "learning_rate = 0.1  \n",
    "seed = np.random.seed(0) # Seed the random number generator for reproducibility\n",
    "p_val = 0.1              # Percent of the overall dataset to reserve for validation\n",
    "p_test = 0.2             # Percent of the overall dataset to reserve for testing\n",
    "\n",
    "margin = 0.4\n",
    "\n",
    "#TODO: Convert to Tensor - you can later add other transformations, such as Scaling here\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        #transforms.RandomResizedCrop(224),\n",
    "        transforms.ToPILImage('L'),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        #transforms.RandomRotation(30),\n",
    "        #transforms.RandomRotation(60),\n",
    "        transforms.Resize([28,28],interpolation=2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "res = models.resnet18(pretrained=True)\n",
    "res.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "res.classifier = Identity()\n",
    "model = SNN(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n",
      "Model on CUDA? True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if your system supports CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 6, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")\n",
    "\n",
    "model = model\n",
    "model = model.to(computing_device)\n",
    "print(\"Model on CUDA?\", next(model.parameters()).is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### need to modify\n",
    "# Setup the training, validation, and testing dataloaders\n",
    "import quickdraw_dataloader as qd\n",
    "from quickdraw_dataloader import create_split_loaders\n",
    "root_dir = \"../data_combine/\"\n",
    "train_loader, val_loader, test_loader = create_split_loaders(root_dir,batch_size, seed, transform=transform, \n",
    "                                                             p_val=p_val, p_test=p_test,\n",
    "                                                             shuffle=True, show_sample=False, \n",
    "                                                             extras=extras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adabound\n",
    "#criterion = nn.CrossEntropyLoss().to(computing_device)\n",
    "criterion = nn.MarginRankingLoss(margin = margin).to(computing_device)\n",
    "\n",
    "#optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001)\n",
    "optimizer = adabound.AdaBound(model.parameters(), lr=1e-3, final_lr=0.1)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader,model,optimizer,criterion):\n",
    "    start = time.time()\n",
    "    sum_loss = 0.0\n",
    "    list_sum_loss = []\n",
    "    correct_overall = 0.0\n",
    "    minbatch_size_ovarall = 0.0\n",
    "    num = 0\n",
    "    for mb_count, (val_images, val_labels) in enumerate(val_loader, 0):\n",
    "        model.eval()\n",
    "        with torch.no_grad():  \n",
    "            optimizer.zero_grad()      \n",
    "            val_images = torch.squeeze(torch.stack([val_images,val_images,val_images], dim=1, out=None))\n",
    "            val_images, val_labels = val_images.to(computing_device), val_labels.to(computing_device)\n",
    "            val_labels = val_labels.type(torch.cuda.FloatTensor)\n",
    "            val_labels = val_labels.long()\n",
    "            outputs = model(val_images)\n",
    "            \n",
    "            loss = criterion(outputs,val_labels)\n",
    "            sum_loss += loss\n",
    "            \n",
    "            output_np = outputs.cpu().detach().numpy()\n",
    "            label_np = val_labels.cpu().detach().numpy()\n",
    "            correct_prediction, minbatch_size = correctness(label_np, output_np)\n",
    "            correct_overall += correct_prediction\n",
    "            minbatch_size_ovarall += minbatch_size\n",
    "    accuracy_vali = correct_overall/minbatch_size_ovarall\n",
    "    print('validatation accuracy',accuracy_vali) \n",
    "    \n",
    "    print(\"validation time = \", time.time()-start)    \n",
    "    return 1.0*sum_loss/mb_count, accuracy_vali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctness(out1, out2):\n",
    "    return np.sum((out1-out2)>margin), out1.shape[0]\n",
    "def train_model(model, criterion,optimizer, scheduler, num_epochs=10,resume=False, direct=\"\"):\n",
    "    since = time.time()\n",
    "    total_loss = []\n",
    "    if resume == False:\n",
    "        avg_minibatch_loss = []\n",
    "        total_vali_loss = []\n",
    "        avg_training_accuracy = []\n",
    "        avg_validation_accuracy = []\n",
    "        epc_save = 0 # MAYBE\n",
    "    else: \n",
    "        print('Resume model: %s' % direct)\n",
    "        check_point = torch.load(direct)\n",
    "        model.load_state_dict(check_point['state_dict'])\n",
    "        optimizer.load_state_dict(check_point['optimizer'])\n",
    "        avg_minibatch_loss = list(np.load('avg_minibatch_loss.npy'))\n",
    "        total_vali_loss = list(np.load('total_vali_loss.npy'))\n",
    "        avg_training_accuracy = list(np.load('avg_training_accuracy.npy'))\n",
    "        avg_validation_accuracy = list(np.load('avg_validation_accuracy.npy'))\n",
    "        epc_save = check_point['epoch']\n",
    "        \n",
    "    tolerence = 3\n",
    "    i = 0 \n",
    "    for epoch in range(epc_save,num_epochs):\n",
    "        N = 100\n",
    "        M = 100000\n",
    "        N_minibatch_loss = 0.0    \n",
    "        best_loss = 100\n",
    "        early_stop = 0\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        correct_overall = 0.0; \n",
    "        minbatch_size_overall = 0.0; \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train']:\n",
    "            scheduler.step()\n",
    "            # Iterate over data.\n",
    "            minibatch_time = time.time()\n",
    "            target = torch.ones(batch_size).to(computing_device)\n",
    "            for minibatch_count, (pos_0,pos_1, neg) in enumerate(train_loader, 0):\n",
    "                pos_0 = torch.squeeze(torch.stack([pos_0,pos_0,pos_0], dim=1, out=None)).to(computing_device)\n",
    "                pos_1 = torch.squeeze(torch.stack([pos_1,pos_1,pos_1], dim=1, out=None)).to(computing_device)\n",
    "                neg = torch.squeeze(torch.stack([neg,neg,neg], dim=1, out=None)).to(computing_device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs_pos = model(pos_0,pos_1)\n",
    "                    outputs_neg = model(pos_0,neg)\n",
    "                    #loss = (outputs_neg - outputs_pos + 0.2).mean()\n",
    "                    loss = criterion(outputs_pos,outputs_neg,target)\n",
    "                    N_minibatch_loss += loss\n",
    "                    # backward + optimize only if in training phase\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    outputs_pos_np = outputs_pos.cpu().detach().numpy()\n",
    "                    outputs_neg_np = outputs_neg.cpu().detach().numpy()\n",
    "                    #print(label_np[1:5])\n",
    "\n",
    "                    correct_prediction, minbatch_size = correctness(outputs_pos_np, outputs_neg_np)\n",
    "                    correct_overall += correct_prediction\n",
    "                    minbatch_size_overall += minbatch_size\n",
    "                # statistics\n",
    "                # training stats\n",
    "                if minibatch_count % N == 0 and minibatch_count!=0:    \n",
    "\n",
    "                    # Print the loss averaged over the last N mini-batches    \n",
    "                    N_minibatch_loss /= N\n",
    "                    print('Epoch %d, average minibatch %d loss: %.3f' %\n",
    "                        (epoch + 1, minibatch_count, N_minibatch_loss))\n",
    "                    accuracy_train = correct_overall/minbatch_size_overall\n",
    "                    print('accuracy',accuracy_train)\n",
    "                    print(\"pos\")\n",
    "                    print(outputs_pos.mean())\n",
    "                    print(\"neg\")\n",
    "                    print(outputs_neg.mean())\n",
    "                    \n",
    "                    # Add the averaged loss over N minibatches and reset the counter\n",
    "                    avg_minibatch_loss.append(N_minibatch_loss)\n",
    "                    avg_minibatch_loss_1 = np.array(avg_minibatch_loss)\n",
    "                    #np.save('avg_minibatch_loss', avg_minibatch_loss_1)\n",
    "                    #avg_training_accuracy.append(accuracy_train)\n",
    "                    #avg_training_accuracy_1 = np.array(avg_training_accuracy)\n",
    "                    #np.save('avg_training_accuracy', avg_training_accuracy)\n",
    "                    \n",
    "                    N_minibatch_loss = 0.0\n",
    "                    correct_overall = 0.0\n",
    "                    minbatch_size_overall = 0.0\n",
    "                    #print('accuracy, precision, recall', accuracy, precision, recall)\n",
    "                    save_checkpoint({'epoch': epoch + 1,\n",
    "                                'state_dict': model.state_dict(),\n",
    "                                'optimizer': optimizer.state_dict(),\n",
    "                                },\n",
    "                                filename='./checkpoint/'+'%d_model_epoch%d.pth' % (epoch , minibatch_count))\n",
    "                    print(N, \"minibatch_time\" , time.time()-minibatch_time)\n",
    "                    minibatch_time = time.time()\n",
    "                #Validation\n",
    "#                 if minibatch_count % M == 0 and minibatch_count!=0:\n",
    "                   \n",
    "#                     v_loss, accuracy_vali = validate(val_loader,model,optimizer,criterion)\n",
    "#                     print(v_loss.item())\n",
    "                    \n",
    "#                     total_vali_loss.append(v_loss.item())\n",
    "#                     avg_validation_accuracy.append(accuracy_vali.item())\n",
    "                    \n",
    "#                     total_vali_loss_1 = np.array(total_vali_loss)\n",
    "#                     np.save('total_vali_loss', total_vali_loss_1)      \n",
    "#                     avg_validation_accuracy_1 = np.array(avg_validation_accuracy)\n",
    "#                     np.save('avg_validation_accuracy', avg_validation_accuracy_1)      \n",
    "                \n",
    "#                     if total_vali_loss[i] > best_loss and i != 0:\n",
    "#                         early_stop += 1\n",
    "#                         if early_stop == tolerence:\n",
    "#                             print('early stop here')\n",
    "#                             break\n",
    "#                     else:\n",
    "#                         best_loss = total_vali_loss[i] \n",
    "#                         early_stop = 0\n",
    "#                     i = i + 1\n",
    "            print(\"Finished\", epoch + 1, \"epochs of training\")\n",
    "    print(\"Training complete after\", epoch, \"epochs\")\n",
    "    \n",
    "    print(\"total_vali_loss\")\n",
    "    print(total_vali_loss)\n",
    "    print(\"avg_minibatch_loss\")\n",
    "    print(avg_minibatch_loss)\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s '.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best=0, filename='models/checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "Epoch 1, average minibatch 100 loss: 0.184\n",
      "accuracy 0.10550742574257425\n",
      "pos\n",
      "tensor(0.7265, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4808, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 82.94691634178162\n",
      "Epoch 1, average minibatch 200 loss: 0.170\n",
      "accuracy 0.0378125\n",
      "pos\n",
      "tensor(0.7293, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 77.85517454147339\n",
      "Epoch 1, average minibatch 300 loss: 0.168\n",
      "accuracy 0.02921875\n",
      "pos\n",
      "tensor(0.7295, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5180, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 76.11269736289978\n",
      "Epoch 1, average minibatch 400 loss: 0.169\n",
      "accuracy 0.02609375\n",
      "pos\n",
      "tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4847, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 76.68541502952576\n",
      "Epoch 1, average minibatch 500 loss: 0.167\n",
      "accuracy 0.016875\n",
      "pos\n",
      "tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4932, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 77.02357196807861\n",
      "Epoch 1, average minibatch 600 loss: 0.166\n",
      "accuracy 0.008125\n",
      "pos\n",
      "tensor(0.7296, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4913, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 76.02845001220703\n",
      "Epoch 1, average minibatch 700 loss: 0.166\n",
      "accuracy 0.00625\n",
      "pos\n",
      "tensor(0.7280, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5144, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 77.89917135238647\n",
      "Epoch 1, average minibatch 800 loss: 0.164\n",
      "accuracy 0.00984375\n",
      "pos\n",
      "tensor(0.7298, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5210, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 79.77641177177429\n",
      "Epoch 1, average minibatch 900 loss: 0.167\n",
      "accuracy 0.01296875\n",
      "pos\n",
      "tensor(0.7289, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5042, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 74.33142471313477\n",
      "Epoch 1, average minibatch 1000 loss: 0.163\n",
      "accuracy 0.01234375\n",
      "pos\n",
      "tensor(0.7299, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4721, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 79.3818039894104\n",
      "Epoch 1, average minibatch 1100 loss: 0.165\n",
      "accuracy 0.00390625\n",
      "pos\n",
      "tensor(0.7295, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4903, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 78.82066464424133\n",
      "Epoch 1, average minibatch 1200 loss: 0.161\n",
      "accuracy 0.009375\n",
      "pos\n",
      "tensor(0.7289, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4885, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 75.1276216506958\n",
      "Epoch 1, average minibatch 1300 loss: 0.163\n",
      "accuracy 0.01015625\n",
      "pos\n",
      "tensor(0.7307, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4766, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 77.17985534667969\n",
      "Epoch 1, average minibatch 1400 loss: 0.162\n",
      "accuracy 0.010625\n",
      "pos\n",
      "tensor(0.7294, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4718, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 77.13370013237\n",
      "Epoch 1, average minibatch 1500 loss: 0.164\n",
      "accuracy 0.00765625\n",
      "pos\n",
      "tensor(0.7306, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4945, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 73.99032163619995\n",
      "Epoch 1, average minibatch 1600 loss: 0.166\n",
      "accuracy 0.00984375\n",
      "pos\n",
      "tensor(0.7302, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4864, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 79.25569677352905\n",
      "Epoch 1, average minibatch 1700 loss: 0.161\n",
      "accuracy 0.00515625\n",
      "pos\n",
      "tensor(0.7298, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 78.94556140899658\n",
      "Epoch 1, average minibatch 1800 loss: 0.163\n",
      "accuracy 0.00703125\n",
      "pos\n",
      "tensor(0.7289, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4638, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 74.98923230171204\n",
      "Epoch 1, average minibatch 1900 loss: 0.167\n",
      "accuracy 0.01078125\n",
      "pos\n",
      "tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5046, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 78.85421991348267\n",
      "Epoch 1, average minibatch 2000 loss: 0.164\n",
      "accuracy 0.00953125\n",
      "pos\n",
      "tensor(0.7295, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5174, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 77.94895124435425\n",
      "Epoch 1, average minibatch 2100 loss: 0.163\n",
      "accuracy 0.0078125\n",
      "pos\n",
      "tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4634, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 74.77262449264526\n",
      "Epoch 1, average minibatch 2200 loss: 0.167\n",
      "accuracy 0.005625\n",
      "pos\n",
      "tensor(0.7298, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5068, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 73.97074317932129\n",
      "Epoch 1, average minibatch 2300 loss: 0.165\n",
      "accuracy 0.006875\n",
      "pos\n",
      "tensor(0.7308, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 77.11711406707764\n",
      "Epoch 1, average minibatch 2400 loss: 0.164\n",
      "accuracy 0.01078125\n",
      "pos\n",
      "tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5260, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 74.76415777206421\n",
      "Epoch 1, average minibatch 2500 loss: 0.159\n",
      "accuracy 0.0203125\n",
      "pos\n",
      "tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4613, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 76.52389526367188\n",
      "Epoch 1, average minibatch 2600 loss: 0.164\n",
      "accuracy 0.01484375\n",
      "pos\n",
      "tensor(0.7297, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4723, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 78.01243424415588\n",
      "Epoch 1, average minibatch 2700 loss: 0.165\n",
      "accuracy 0.0134375\n",
      "pos\n",
      "tensor(0.7307, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5082, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 73.75576567649841\n",
      "Epoch 1, average minibatch 2800 loss: 0.160\n",
      "accuracy 0.01109375\n",
      "pos\n",
      "tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4537, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 76.33181691169739\n",
      "Epoch 1, average minibatch 2900 loss: 0.163\n",
      "accuracy 0.0078125\n",
      "pos\n",
      "tensor(0.7306, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4843, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 77.56770920753479\n",
      "Epoch 1, average minibatch 3000 loss: 0.166\n",
      "accuracy 0.0065625\n",
      "pos\n",
      "tensor(0.7298, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4943, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 75.0484209060669\n",
      "Epoch 1, average minibatch 3100 loss: 0.164\n",
      "accuracy 0.00296875\n",
      "pos\n",
      "tensor(0.7306, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4917, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 77.00276851654053\n",
      "Epoch 1, average minibatch 3200 loss: 0.163\n",
      "accuracy 0.00421875\n",
      "pos\n",
      "tensor(0.7308, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4726, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 74.8873941898346\n",
      "Epoch 1, average minibatch 3300 loss: 0.166\n",
      "accuracy 0.005\n",
      "pos\n",
      "tensor(0.7291, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4866, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 74.80436325073242\n",
      "Epoch 1, average minibatch 3400 loss: 0.164\n",
      "accuracy 0.00328125\n",
      "pos\n",
      "tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4962, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 77.5036129951477\n",
      "Epoch 1, average minibatch 3500 loss: 0.162\n",
      "accuracy 0.0034375\n",
      "pos\n",
      "tensor(0.7302, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4831, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 78.20902705192566\n",
      "Epoch 1, average minibatch 3600 loss: 0.162\n",
      "accuracy 0.0065625\n",
      "pos\n",
      "tensor(0.7305, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4978, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 73.4996120929718\n",
      "Epoch 1, average minibatch 3700 loss: 0.165\n",
      "accuracy 0.00375\n",
      "pos\n",
      "tensor(0.7295, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5027, device='cuda:0', grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 minibatch_time 78.08874773979187\n",
      "Epoch 1, average minibatch 3800 loss: 0.161\n",
      "accuracy 0.00328125\n",
      "pos\n",
      "tensor(0.7296, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5202, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 79.51268315315247\n",
      "Epoch 1, average minibatch 3900 loss: 0.164\n",
      "accuracy 0.0034375\n",
      "pos\n",
      "tensor(0.7306, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4846, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 75.12973213195801\n",
      "Epoch 1, average minibatch 4000 loss: 0.161\n",
      "accuracy 0.003125\n",
      "pos\n",
      "tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 77.73069453239441\n",
      "Epoch 1, average minibatch 4100 loss: 0.161\n",
      "accuracy 0.00359375\n",
      "pos\n",
      "tensor(0.7307, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4917, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 78.74428534507751\n",
      "Epoch 1, average minibatch 4200 loss: 0.162\n",
      "accuracy 0.00375\n",
      "pos\n",
      "tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4924, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 75.785635471344\n",
      "Epoch 1, average minibatch 4300 loss: 0.162\n",
      "accuracy 0.0040625\n",
      "pos\n",
      "tensor(0.7302, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4731, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 77.91293621063232\n",
      "Epoch 1, average minibatch 4400 loss: 0.165\n",
      "accuracy 0.003125\n",
      "pos\n",
      "tensor(0.7305, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4768, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 78.84932255744934\n",
      "Epoch 1, average minibatch 4500 loss: 0.162\n",
      "accuracy 0.0046875\n",
      "pos\n",
      "tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4706, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 73.09155678749084\n",
      "Epoch 1, average minibatch 4600 loss: 0.164\n",
      "accuracy 0.0028125\n",
      "pos\n",
      "tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4795, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 77.55148530006409\n",
      "Epoch 1, average minibatch 4700 loss: 0.162\n",
      "accuracy 0.00390625\n",
      "pos\n",
      "tensor(0.7307, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5143, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 77.75531792640686\n",
      "Epoch 1, average minibatch 4800 loss: 0.164\n",
      "accuracy 0.00296875\n",
      "pos\n",
      "tensor(0.7307, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4549, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 75.66883182525635\n",
      "Epoch 1, average minibatch 4900 loss: 0.165\n",
      "accuracy 0.0034375\n",
      "pos\n",
      "tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5236, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Epoch 1, average minibatch 5100 loss: 0.163\n",
      "accuracy 0.00375\n",
      "pos\n",
      "tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4951, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 74.08319640159607\n",
      "Epoch 1, average minibatch 5200 loss: 0.162\n",
      "accuracy 0.00359375\n",
      "pos\n",
      "tensor(0.7308, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5152, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 78.09096336364746\n",
      "Epoch 1, average minibatch 5300 loss: 0.165\n",
      "accuracy 0.00421875\n",
      "pos\n",
      "tensor(0.7308, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4800, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 76.55616188049316\n",
      "Epoch 1, average minibatch 5400 loss: 0.161\n",
      "accuracy 0.00546875\n",
      "pos\n",
      "tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5165, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 74.2396559715271\n",
      "Epoch 1, average minibatch 5500 loss: 0.164\n",
      "accuracy 0.004375\n",
      "pos\n",
      "tensor(0.7305, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4861, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 74.2155818939209\n",
      "Epoch 1, average minibatch 5600 loss: 0.162\n",
      "accuracy 0.00375\n",
      "pos\n",
      "tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4922, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 77.16904401779175\n",
      "Epoch 1, average minibatch 5700 loss: 0.162\n",
      "accuracy 0.00296875\n",
      "pos\n",
      "tensor(0.7302, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 75.81261277198792\n",
      "Epoch 1, average minibatch 5800 loss: 0.159\n",
      "accuracy 0.00453125\n",
      "pos\n",
      "tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4866, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 74.41626167297363\n",
      "Epoch 1, average minibatch 5900 loss: 0.162\n",
      "accuracy 0.00375\n",
      "pos\n",
      "tensor(0.7306, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4694, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 77.51268362998962\n",
      "Epoch 1, average minibatch 6000 loss: 0.162\n",
      "accuracy 0.0040625\n",
      "pos\n",
      "tensor(0.7302, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4585, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 74.84537887573242\n",
      "Epoch 1, average minibatch 6100 loss: 0.165\n",
      "accuracy 0.00421875\n",
      "pos\n",
      "tensor(0.7300, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4732, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 75.03337049484253\n",
      "Epoch 1, average minibatch 6200 loss: 0.162\n",
      "accuracy 0.00390625\n",
      "pos\n",
      "tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5178, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 78.76473093032837\n",
      "Epoch 1, average minibatch 6300 loss: 0.162\n",
      "accuracy 0.004375\n",
      "pos\n",
      "tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 72.03836941719055\n",
      "Epoch 1, average minibatch 6400 loss: 0.161\n",
      "accuracy 0.00765625\n",
      "pos\n",
      "tensor(0.7300, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5112, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 75.78450083732605\n",
      "Epoch 1, average minibatch 6500 loss: 0.165\n",
      "accuracy 0.00375\n",
      "pos\n",
      "tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4726, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 77.4483630657196\n",
      "Epoch 1, average minibatch 6600 loss: 0.163\n",
      "accuracy 0.0059375\n",
      "pos\n",
      "tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5070, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 75.23879933357239\n",
      "Epoch 1, average minibatch 6700 loss: 0.161\n",
      "accuracy 0.00546875\n",
      "pos\n",
      "tensor(0.7302, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5185, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 75.70678329467773\n",
      "Epoch 1, average minibatch 6800 loss: 0.165\n",
      "accuracy 0.004375\n",
      "pos\n",
      "tensor(0.7308, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 76.59812784194946\n",
      "Epoch 1, average minibatch 6900 loss: 0.161\n",
      "accuracy 0.004375\n",
      "pos\n",
      "tensor(0.7307, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4828, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 73.57452440261841\n",
      "Epoch 1, average minibatch 7000 loss: 0.160\n",
      "accuracy 0.00671875\n",
      "pos\n",
      "tensor(0.7300, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4968, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 71.45733737945557\n",
      "Epoch 1, average minibatch 7100 loss: 0.160\n",
      "accuracy 0.0053125\n",
      "pos\n",
      "tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4982, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 75.01411843299866\n",
      "Epoch 1, average minibatch 7200 loss: 0.162\n",
      "accuracy 0.00671875\n",
      "pos\n",
      "tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4924, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 71.82248735427856\n",
      "Epoch 1, average minibatch 7300 loss: 0.162\n",
      "accuracy 0.005625\n",
      "pos\n",
      "tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4912, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 75.7273006439209\n",
      "Epoch 1, average minibatch 7400 loss: 0.165\n",
      "accuracy 0.00390625\n",
      "pos\n",
      "tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 81.45209789276123\n",
      "Epoch 1, average minibatch 7500 loss: 0.164\n",
      "accuracy 0.00578125\n",
      "pos\n",
      "tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4724, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 75.2614381313324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, average minibatch 7600 loss: 0.162\n",
      "accuracy 0.005\n",
      "pos\n",
      "tensor(0.7310, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4862, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 74.75314378738403\n",
      "Epoch 1, average minibatch 7700 loss: 0.164\n",
      "accuracy 0.006875\n",
      "pos\n",
      "tensor(0.7306, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4790, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 74.2221326828003\n",
      "Epoch 1, average minibatch 7800 loss: 0.162\n",
      "accuracy 0.0071875\n",
      "pos\n",
      "tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 74.84983777999878\n",
      "Epoch 1, average minibatch 7900 loss: 0.162\n",
      "accuracy 0.0040625\n",
      "pos\n",
      "tensor(0.7308, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5022, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 71.95773530006409\n",
      "Epoch 1, average minibatch 8000 loss: 0.163\n",
      "accuracy 0.00359375\n",
      "pos\n",
      "tensor(0.7308, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.5396, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 72.65101289749146\n",
      "Epoch 1, average minibatch 8100 loss: 0.162\n",
      "accuracy 0.0034375\n",
      "pos\n",
      "tensor(0.7307, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4900, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 78.21440148353577\n",
      "Epoch 1, average minibatch 8200 loss: 0.164\n",
      "accuracy 0.00734375\n",
      "pos\n",
      "tensor(0.7306, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "neg\n",
      "tensor(0.4813, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "100 minibatch_time 73.6161048412323\n"
     ]
    }
   ],
   "source": [
    "model_trained = train_model(model, criterion,optimizer, exp_lr_scheduler, num_epochs=20,resume=False,direct='./checkpoint/4_model_epoch2600.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
